{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use conda env minimap_conda_env.yml to create conda env for this script\n",
    "#This is an example script of processing mapped MC-3C data for further analysis\n",
    "#It is run from within the 'scripts' subdirectory, using following directory structure:\n",
    "#Analysis_Dir\n",
    "#├── data\n",
    "#    ├── permutations\n",
    "#├── alignments\n",
    "#├── figures\n",
    "#├── scripts\n",
    "#├── lsf_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import bioframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.gridspec import GridSpecFromSubplotSpec\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignmentDir = #path_to_alignments\n",
    "outDataDir = #out_data_path\n",
    "compartmentDataDir = #path_to_compartment_eigenvector\n",
    "\n",
    "#### This section (below) will change depending on specific samples ####\n",
    "conditions = [\n",
    "    't0Mit_R1_T1',\n",
    "    't2_R1',\n",
    "    't4DMSO_R1',\n",
    "    't4ICRF_R1',\n",
    "    't8DMSO_R1',\n",
    "    't8ICRF_R1',\n",
    "    't0Mit_R1_T2',\n",
    "    't0Mit_R2',\n",
    "    't2_R2',\n",
    "    't4DMSO_R2',\n",
    "    't4ICRF_R2',\n",
    "    't8DMSO_R2',\n",
    "    't8ICRF_R2',\n",
    "    't0Mit_R3',\n",
    "    't2_R3',\n",
    "    't4DMSO_R3',\n",
    "    't4ICRF_R3',\n",
    "    't8DMSO_R3',\n",
    "    't8ICRF_R3'\n",
    "]\n",
    "\n",
    "long_names = {\n",
    "    't0Mit_R1_T1' : 'TI-MC3C-Dpn-t0Mit-4-30',\n",
    "    't2_R1' : 'TI-MC3C-Dpn-t2-4-30',\n",
    "    't4DMSO_R1' : 'TI-MC3C-Dpn-t4DMSO-4-30',\n",
    "    't4ICRF_R1' : 'TI-MC3C-Dpn-t4ICRF-4-30',\n",
    "    't8DMSO_R1' : 'TI-MC3C-Dpn-t8DMSO-4-30',\n",
    "    't8ICRF_R1' : 'TI-MC3C-Dpn-t8ICRF-4-30',\n",
    "    't0Mit_R1_T2' : 'TI-MC3C-Dpn-t0Mit-4-30-T2',\n",
    "    't0Mit_R2' : 'TI-MC3C-Dpn-t0Mit-4-39',\n",
    "    't2_R2' : 'TI-MC3C-Dpn-t2-4-39',\n",
    "    't4DMSO_R2' : 'TI-MC3C-Dpn-t4DMSO-4-39',\n",
    "    't4ICRF_R2' : 'TI-MC3C-Dpn-t4ICRF-4-39',\n",
    "    't8DMSO_R2' : 'TI-MC3C-Dpn-t8DMSO-4-39',\n",
    "    't8ICRF_R2' : 'TI-MC3C-Dpn-t8ICRF-4-39',\n",
    "    't0Mit_R3' : 'TI-MC3C-Dpn-t0Mit-R3-5-14',\n",
    "    't2_R3' : 'TI-MC3C-Dpn-t2-R3-5-14',\n",
    "    't4DMSO_R3' : 'TI-MC3C-Dpn-t4DMSO-R3-5-14',\n",
    "    't4ICRF_R3' : 'TI-MC3C-Dpn-t4ICRF-R3-5-14',\n",
    "    't8DMSO_R3' : 'TI-MC3C-Dpn-t8DMSO-R3-5-14',\n",
    "    't8ICRF_R3' : 'TI-MC3C-Dpn-t8ICRF-R3-5-14'\n",
    "}\n",
    "\n",
    "#All using t8DMSO R1R2 eigen\n",
    "eigs_conds = [\n",
    "    't8DMSO_R1R2'\n",
    "]\n",
    "\n",
    "eigs_long_names = {\n",
    "    't8DMSO_R1R2' : 'TI-HiC-Dpn-HeLa-MitoticRelease-t8hr-DMSO-6hr-G1Sort-R1R2'\n",
    "}\n",
    "\n",
    "eigs_to_conditions = {\n",
    "    't0Mit_R1_T1' : 't8DMSO_R1R2',\n",
    "    't2_R1' : 't8DMSO_R1R2',\n",
    "    't4DMSO_R1' : 't8DMSO_R1R2',\n",
    "    't4ICRF_R1' : 't8DMSO_R1R2',\n",
    "    't8DMSO_R1' : 't8DMSO_R1R2',\n",
    "    't8ICRF_R1' : 't8DMSO_R1R2',\n",
    "    't0Mit_R1_T2' : 't8DMSO_R1R2',\n",
    "    't0Mit_R2' : 't8DMSO_R1R2',\n",
    "    't2_R2' : 't8DMSO_R1R2',\n",
    "    't4DMSO_R2' : 't8DMSO_R1R2',\n",
    "    't4ICRF_R2' : 't8DMSO_R1R2',\n",
    "    't8DMSO_R2' : 't8DMSO_R1R2',\n",
    "    't8ICRF_R2' : 't8DMSO_R1R2',\n",
    "    't0Mit_R3': 't8DMSO_R1R2',\n",
    "    't2_R3': 't8DMSO_R1R2',\n",
    "    't4DMSO_R3': 't8DMSO_R1R2',\n",
    "    't4ICRF_R3': 't8DMSO_R1R2',\n",
    "    't8DMSO_R3': 't8DMSO_R1R2',\n",
    "    't8ICRF_R3': 't8DMSO_R1R2',\n",
    "}\n",
    "#### This section (above) will change depending on specific samples ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load alignments\n",
    "#Completely unaligned walks are dropped from this output, but walks may have unaligned steps which are just not shown...\n",
    "#Only primary alignments are shown in this output\n",
    "output_filenames = {}\n",
    "for cond in conditions:\n",
    "    output_filenames[cond] = f'{alignmentDir}/{long_names[cond]}.hg38.minimap2.output.paf'\n",
    "\n",
    "#Read in walks as pandas dataframes\n",
    "raw_walk_dfs = {}\n",
    "for cond in conditions:\n",
    "    raw_walk_dfs[cond] = pd.read_csv(output_filenames[cond], sep = '\\t', header = None)\n",
    "\n",
    "#add column names                                     \n",
    "for cond in conditions:\n",
    "    raw_walk_dfs[cond].columns = ['Query_Name', 'Query_Length', 'Query_Start', 'Query_End',\n",
    "                                  'Strand', 'chrom', 'Target_ChrSize', 'start', \n",
    "                                  'end', 'Match_Length', 'Alignment_Length', 'Mapping_Quality', 13, 14, 15, 16, 17, 18]    \n",
    "    \n",
    "#Nicer to sort by position in walk instead of position in genome - fast! Don't need to group. \n",
    "sorted_dfs = {}\n",
    "for cond in conditions:\n",
    "    sorted_dfs[cond] = raw_walk_dfs[cond].sort_values(['Query_Name', 'Query_Start']).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the annotations needed for splitting walk by first_x read length\n",
    "annotated_dfs = {}\n",
    "for cond in conditions:\n",
    "    df = sorted_dfs[cond].iloc[:, 0:12].copy()\n",
    "    grouped_df = df.groupby(by = 'Query_Name')\n",
    "    df['Fragment_Index'] = grouped_df.cumcount()\n",
    "    \n",
    "    summary_table = pd.DataFrame()\n",
    "    summary_table['Fragment_Number'] = grouped_df.size()\n",
    "    \n",
    "    df2 = df.merge(summary_table['Fragment_Number'], left_on = 'Query_Name', right_index = True)\n",
    "    annotated_dfs[cond] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split full walks based on number of fragments, run summary separately for each set\n",
    "#Only using first 2, 3, 4, 5, 6, 7, 8, 9, 10 fragments of all walks\n",
    "fragment_nums = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "real_walks_firstx_length = {}\n",
    "\n",
    "for cond in conditions:\n",
    "    real_walks_firstx_length[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = annotated_dfs[cond].copy()\n",
    "    \n",
    "        #Subset to only first num fragments of each walk\n",
    "        df2 = df[(df['Fragment_Number'] >= num) & (df['Fragment_Index'] < num)]\n",
    "\n",
    "        real_walks_firstx_length[cond][f'length_{num}'] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate walks with largest step size - to use for intermingling/entanglement analysis - first X walks\n",
    "stepsize_dfs = {}\n",
    "\n",
    "for cond in conditions:\n",
    "    stepsize_dfs[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = real_walks_firstx_length[cond][f'length_{num}'].copy()\n",
    "\n",
    "        df['mid'] = (df['start'].copy() + df['end'].copy())//2\n",
    "        df['dist'] = df.mid.diff()\n",
    "        df['dist'].iloc[np.where(df['Query_Name'] != df['Query_Name'].shift())] = np.nan\n",
    "        df['dist'].iloc[np.where(df['chrom'] != df['chrom'].shift())] = np.nan\n",
    "        \n",
    "        #Adding in whether a step changes chromosomes\n",
    "        df['Trans_Step'] = df['chrom'] != df['chrom'].shift()\n",
    "        df['Trans_Step'].iloc[np.where(df['Query_Name'] != df['Query_Name'].shift())] = False \n",
    "        \n",
    "        #adding absolute distance of step as well\n",
    "        df['Abs_Dist'] = abs(df['dist'].copy())\n",
    "        \n",
    "        grouped_df = df.groupby(by = 'Query_Name')\n",
    "        summary_table1 = pd.DataFrame()\n",
    "\n",
    "        #size of largest step in walk\n",
    "        summary_table1['Largest_Step'] = grouped_df['Abs_Dist'].max()\n",
    "        df = df.join(summary_table1, on = 'Query_Name')\n",
    "        \n",
    "        #whether a fragment is part of largest step\n",
    "        df['Largest_Step_Fragment_Start'] = (df['Abs_Dist'] == df['Largest_Step']).shift(-1)\n",
    "        df['Largest_Step_Fragment_End'] = (df['Abs_Dist'] == df['Largest_Step'])\n",
    "        \n",
    "        #Filter out reads where more than one step is the same size as the largest step - there are a few of these\n",
    "        summary_table1 = pd.DataFrame()\n",
    "        \n",
    "        grouped_df = df.groupby(by = 'Query_Name')\n",
    "        summary_table1['Num_Largest_Steps'] = grouped_df['Largest_Step_Fragment_Start'].sum().astype(int)\n",
    "        \n",
    "        df = df.join(summary_table1, on = 'Query_Name')\n",
    "        df = df[df['Num_Largest_Steps'] == 1]\n",
    "        \n",
    "       #midpoint of start of largest step fragment\n",
    "        midpoint_start = df.loc[df['Largest_Step_Fragment_Start'] == True, ['Query_Name', 'mid']]\n",
    "        midpoint_start = midpoint_start.set_index('Query_Name', drop = True)\n",
    "\n",
    "        #midpoint of end of largest step fragment\n",
    "        midpoint_end = df.loc[df['Largest_Step_Fragment_End'] == True, ['Query_Name', 'mid']]\n",
    "        midpoint_end = midpoint_end.set_index('Query_Name', drop = True)\n",
    "\n",
    "        df = df.join(midpoint_start, on = 'Query_Name', rsuffix = '_Largest_Step_Start')\n",
    "        df = df.join(midpoint_end, on = 'Query_Name', rsuffix = '_Largest_Step_End')\n",
    "\n",
    "        #absolute distance from each fragment to start of largest step\n",
    "        df['Distance_To_Largest_Step_Start'] = abs(df['mid_Largest_Step_Start'].copy() - df['mid'].copy())\n",
    "\n",
    "        #distance from each fragment to end of largest step\n",
    "        df['Distance_To_Largest_Step_End'] = abs(df['mid_Largest_Step_End'].copy() - df['mid'].copy())  \n",
    "\n",
    "        stepsize_dfs[cond][f'length_{num}'] = df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate walks - add compartment info for each fragment - t8 DMSO R1R2 eigens, from Hi-C of 2 replicates combined\n",
    "#100kb eigens\n",
    "eigs = {}\n",
    "for cond in eigs_conds:\n",
    "    eigs[cond] = pd.read_csv(f'{compartmentDataDir}/{eigs_long_names[cond]}.100kb.mapq30.byarm.allchroms.eigs.cis.vecs.txt',\n",
    "                  sep = '\\t')\n",
    "    \n",
    "#calling A vs B compartments in each sample\n",
    "eigsA = {}\n",
    "eigsB = {}\n",
    "\n",
    "for cond in eigs_conds:\n",
    "    eigsA[cond] = eigs[cond][eigs[cond]['E1'] > 0]\n",
    "    eigsB[cond] = eigs[cond][eigs[cond]['E1'] < 0]\n",
    "\n",
    "\n",
    "#Merge adjacent bins into one compartment region, give each a unique index - unique across both types\n",
    "eigsA_Ranges = {}\n",
    "eigsB_Ranges = {}\n",
    "\n",
    "for cond in eigs_conds:\n",
    "    eigsA_Ranges[cond] = bioframe.merge(eigsA[cond][['chrom', 'start', 'end']], min_dist = 0).reset_index(drop = True)\n",
    "    eigsA_Ranges[cond]['comp_type'] = 'A'\n",
    "    \n",
    "    eigsB_Ranges[cond] = bioframe.merge(eigsB[cond][['chrom', 'start', 'end']], min_dist = 0).reset_index(drop = True)\n",
    "    eigsB_Ranges[cond]['comp_type'] = 'B'\n",
    "\n",
    "#Combine A and B to get unique indices, then split again for overlaps\n",
    "eigsAB_Ranges = {}\n",
    "\n",
    "for cond in eigs_conds:\n",
    "    eigsAB_Ranges[cond] = eigsA_Ranges[cond].append(eigsB_Ranges[cond]).reset_index(drop=True).reset_index()\n",
    "    eigsAB_Ranges[cond].columns = ['comp_index', 'chrom', 'start', 'end', 'n_intervals', 'comp_type']\n",
    "\n",
    "eigsA_Ranges = {}\n",
    "eigsB_Ranges = {}\n",
    "\n",
    "for cond in eigs_conds:\n",
    "    eigsA_Ranges[cond] = eigsAB_Ranges[cond][eigsAB_Ranges[cond]['comp_type'] == 'A']\n",
    "    eigsB_Ranges[cond] = eigsAB_Ranges[cond][eigsAB_Ranges[cond]['comp_type'] == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlap A and B ranges with cwalk steps - assign each step as A or B based on overlap, change '0' to np.nan\n",
    "#Add compartment index\n",
    "\n",
    "overlap_dfs = {} #slow, but better here than doing compartment type again for each iteration\n",
    "for cond in conditions:\n",
    "    overlap_dfs[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = stepsize_dfs[cond][f'length_{num}'].copy()\n",
    "        overlapA = bioframe.overlap(df, eigsA_Ranges[eigs_to_conditions[cond]], how = 'left', suffixes = ('', '_A'), \n",
    "                                keep_order = True)\n",
    "        overlapAB = bioframe.overlap(overlapA, eigsB_Ranges[eigs_to_conditions[cond]], how = 'left', suffixes = ('', '_B'),\n",
    "                                     keep_order = True)\n",
    "        overlapAB['Frag_Comp_Type'] = 0\n",
    "        overlapAB.loc[~overlapAB['comp_index_A'].isna(), 'Frag_Comp_Type'] = 'A'\n",
    "        overlapAB.loc[~overlapAB['comp_index_B'].isna(), 'Frag_Comp_Type'] = 'B'\n",
    "        overlapAB['Frag_Comp_Index'] = np.nan\n",
    "        overlapAB.loc[~overlapAB['comp_index_A'].isna(), 'Frag_Comp_Index'] = overlapAB['comp_index_A'].copy()\n",
    "        overlapAB.loc[~overlapAB['comp_index_B'].isna(), 'Frag_Comp_Index'] = overlapAB['comp_index_B'].copy()\n",
    "        df = overlapAB.drop(labels = ['comp_index_A', 'chrom_A', 'start_A', 'end_A', 'n_intervals_A', 'comp_index_B', 'chrom_B',\n",
    "                                      'start_B', 'end_B', 'n_intervals_B', 'comp_type_A', 'comp_type_B'], axis = 1)\n",
    "\n",
    "        #Compartment Type of entire walk - A, B, AB, NA\n",
    "        grouped_df = df.groupby(by = 'Query_Name')\n",
    "        summary_table = pd.DataFrame()\n",
    "        comp_types = []\n",
    "        for key,group_df in grouped_df:\n",
    "            comps = group_df['Frag_Comp_Type'].unique().tolist()\n",
    "            comps = ''.join(sorted([str(i) for i in comps]))\n",
    "            comp_types.append(comps)\n",
    "        summary_table['Walk_Comp_Type'] = comp_types\n",
    "        summary_table['Query_Name'] = grouped_df['Query_Name'].first().values\n",
    "        summary_table.loc[summary_table['Walk_Comp_Type'].isin(['0', '0A', '0B', '0AB']), 'Walk_Comp_Type'] = np.nan\n",
    "        df = df.merge(summary_table, on = 'Query_Name')\n",
    "        overlap_dfs[cond][f'length_{num}'] = df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next add annotations to each fragment and summarize walks\n",
    "overlap_dfs2 = {}\n",
    "for cond in conditions:\n",
    "    overlap_dfs2[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = overlap_dfs[cond][f'length_{num}'].copy()\n",
    "\n",
    "        #Adding in whether a step changes compartment type, or compartment index\n",
    "        df['Inter_Comp_Type_Step'] = df['Frag_Comp_Type'] != df['Frag_Comp_Type'].shift()\n",
    "        df['Inter_Comp_Type_Step'].iloc[np.where(df['Query_Name'] != df['Query_Name'].shift())] = np.nan\n",
    "\n",
    "        df['Inter_Comp_Index_Step'] = df['Frag_Comp_Index'] != df['Frag_Comp_Index'].shift()\n",
    "        df['Inter_Comp_Index_Step'].iloc[np.where(df['Query_Name'] != df['Query_Name'].shift())] = np.nan\n",
    "        overlap_dfs2[cond][f'length_{num}'] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next add annotations to each fragment based on how far fragment is from either side of largest step\n",
    "overlap_dfs3 = {}\n",
    "for cond in conditions:\n",
    "    overlap_dfs3[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = overlap_dfs2[cond][f'length_{num}'].copy()\n",
    "\n",
    "        #is the step within 1/4 of largest step size from start of the largest step?\n",
    "        df['Near_Largest_Step_Start_Step'] = df['Distance_To_Largest_Step_Start'] < df['Largest_Step']//4\n",
    "\n",
    "        #is the step within 1/4 of largest step size from end of the largest step?\n",
    "        df['Near_Largest_Step_End_Step'] = df['Distance_To_Largest_Step_End'] < df['Largest_Step']//4\n",
    "\n",
    "        #If the fragment is close to one end of the largest step, was the step between the two regions, or within one region?\n",
    "        df['Inter_Largest_Step_Side_Step'] = df['Near_Largest_Step_Start_Step'] != df['Near_Largest_Step_Start_Step'].shift()\n",
    "        df['Inter_Largest_Step_Side_Step'].iloc[np.where(df['Query_Name'] != df['Query_Name'].shift())] = np.nan\n",
    "        df['Inter_Largest_Step_Side_Step'].iloc[np.where((df['Near_Largest_Step_Start_Step'] == False) &\n",
    "                                                         (df['Near_Largest_Step_End_Step'] == False))] = np.nan\n",
    "\n",
    "        overlap_dfs3[cond][f'length_{num}'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_walks = {}\n",
    "\n",
    "for cond in conditions:\n",
    "    summarized_walks[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        summary_table = pd.DataFrame()\n",
    "        grouped_df = overlap_dfs3[cond][f'length_{num}'].groupby('Query_Name')\n",
    "\n",
    "        #Number of fragments in walk close to the two sides of the largest step\n",
    "        summary_table['Near_Largest_Step_Start_Frag_Num'] = grouped_df['Near_Largest_Step_Start_Step'].sum().astype(int)\n",
    "        summary_table['Near_Largest_Step_End_Frag_Num'] = grouped_df['Near_Largest_Step_End_Step'].sum().astype(int)\n",
    "\n",
    "        #Number of steps between sides of largest step\n",
    "        summary_table['Inter_Largest_Step_Side_Step_Num'] = grouped_df['Inter_Largest_Step_Side_Step'].sum().astype(int)\n",
    "\n",
    "        #Indicate how many fragments are close to one of the two sides\n",
    "        summary_table['Near_Largest_Step_Either_Side_Frag_Num'] = summary_table['Near_Largest_Step_Start_Frag_Num'] + summary_table['Near_Largest_Step_End_Frag_Num']\n",
    "\n",
    "        #Number of chromosomes visited\n",
    "        summary_table['Chrom_Number'] = grouped_df['chrom'].nunique()\n",
    "\n",
    "        #Number of compartment types visited\n",
    "        summary_table['Comp_Type_Number'] = grouped_df['Frag_Comp_Type'].nunique()\n",
    "\n",
    "        #Number of compartment indices visited\n",
    "        summary_table['Comp_Index_Number'] = grouped_df['Frag_Comp_Index'].nunique()\n",
    "\n",
    "        #span, cis walks only\n",
    "        summary_table['MaxCoord'] = grouped_df['end'].max()\n",
    "        summary_table['MinCoord'] = grouped_df['start'].min()\n",
    "        summary_table['Span'] = summary_table['MaxCoord'] - summary_table['MinCoord']\n",
    "        #Set to nan for walks with more than 1 chromosome\n",
    "        summary_table.loc[summary_table['Chrom_Number'] > 1, 'Span'] = np.nan\n",
    "\n",
    "        #Sum of distances, cis walks only\n",
    "        summary_table['Sum_Dists'] = grouped_df['dist'].apply(lambda x: np.sum(np.abs(x)))\n",
    "        #Set to nan for walks with more than 1 chromosome\n",
    "        summary_table.loc[summary_table['Chrom_Number'] > 1, 'Sum_Dists'] = np.nan\n",
    "\n",
    "        #Number of inter chromosomal steps\n",
    "        summary_table['Trans_Steps'] = grouped_df['Trans_Step'].sum().astype(int)\n",
    "\n",
    "        #Number of inter compartment type steps\n",
    "        summary_table['Inter_Compartment_Type_Steps'] = grouped_df['Inter_Comp_Type_Step'].sum().astype(int)\n",
    "\n",
    "        #Number of inter compartment index steps in walk - also includes switches between compartment types\n",
    "        summary_table['Inter_Compartment_Index_Steps'] = grouped_df['Inter_Comp_Index_Step'].sum().astype(int)\n",
    "\n",
    "        summarized_walks[cond][f'length_{num}'] = summary_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge full walks with summarized walks for all walk lengths to save\n",
    "full_walks_with_summary = {}\n",
    "for cond in conditions:\n",
    "    full_walks_with_summary[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        full_walks_with_summary[cond][f'length_{num}'] = overlap_dfs3[cond][f'length_{num}'].merge(summarized_walks[cond][f'length_{num}'], left_on = 'Query_Name', right_on = 'Query_Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_walks_with_summary_firstx_length_fractions = {}\n",
    "for cond in conditions:\n",
    "    real_walks_with_summary_firstx_length_fractions[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        df = full_walks_with_summary[cond][f'length_{num}']\n",
    "        #Add max fraction of fragments within one compartment index\n",
    "        df1 = df.groupby(['Query_Name', 'Frag_Comp_Index']).agg(\n",
    "            {'Query_Length' : 'count', \n",
    "             'Fragment_Number' : 'mean'}).reset_index().groupby('Query_Name').max().reset_index()\n",
    "\n",
    "        df1['Max_OneCompIndex_FracOfFragments'] = df1['Query_Length']/num\n",
    "        df_filter1 = df.merge(df1[['Query_Name', 'Max_OneCompIndex_FracOfFragments']], on = 'Query_Name')\n",
    "\n",
    "        #Add max fraction of fragments within one chromosome\n",
    "        df2 = df.groupby(['Query_Name', 'chrom']).agg(\n",
    "            {'Query_Length' : 'count', \n",
    "             'Fragment_Number' : 'mean'}).reset_index().groupby('Query_Name').max().reset_index()\n",
    "\n",
    "        df2['Max_OneChrom_FracOfFragments'] = df2['Query_Length']/num\n",
    "        df_filter2 = df_filter1.merge(df2[['Query_Name', 'Max_OneChrom_FracOfFragments']], on = 'Query_Name')\n",
    "        \n",
    "        #add max fraction of fragments near to one side of largest step\n",
    "        df3 = df.groupby(['Query_Name']).agg({\n",
    "            'Near_Largest_Step_Start_Frag_Num' : 'mean',\n",
    "            'Near_Largest_Step_End_Frag_Num' : 'mean'}).reset_index()\n",
    "        \n",
    "        df3['Max_NearOneLargestStepEnd_FracOfFragments'] = df3[['Near_Largest_Step_Start_Frag_Num', 'Near_Largest_Step_End_Frag_Num']].max(axis = 1)/num\n",
    "        df_filter3 = df_filter2.merge(df3[['Query_Name', 'Max_NearOneLargestStepEnd_FracOfFragments']], on = 'Query_Name')\n",
    "\n",
    "\n",
    "        real_walks_with_summary_firstx_length_fractions[cond][f'length_{num}'] = df_filter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make filtered summary from permuted_walks_with_summary_filtered\n",
    "real_walks_summarized_firstx_length = {}\n",
    "for cond in conditions:\n",
    "    real_walks_summarized_firstx_length[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        real_walks_summarized_firstx_length[cond][f'length_{num}'] = real_walks_with_summary_firstx_length_fractions[cond][f'length_{num}'][[\n",
    "            'Query_Name',\n",
    "            'chrom',\n",
    "            'Fragment_Number',\n",
    "            'Chrom_Number',\n",
    "            'Comp_Type_Number',\n",
    "            'Comp_Index_Number',\n",
    "            'Near_Largest_Step_Either_Side_Frag_Num',\n",
    "            'MaxCoord',\n",
    "            'MinCoord',\n",
    "            'Largest_Step',\n",
    "            'Span',\n",
    "            'Sum_Dists',\n",
    "            'Walk_Comp_Type',\n",
    "            'Trans_Steps',\n",
    "            'Inter_Compartment_Type_Steps',\n",
    "            'Inter_Compartment_Index_Steps',\n",
    "            'Inter_Largest_Step_Side_Step_Num',\n",
    "            'Max_OneCompIndex_FracOfFragments',\n",
    "            'Max_OneChrom_FracOfFragments',\n",
    "            'Max_NearOneLargestStepEnd_FracOfFragments']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make filtered summary from permuted_walks_with_summary_filtered\n",
    "overlap_df_for_permutations = {}\n",
    "for cond in conditions:\n",
    "    overlap_df_for_permutations[cond] = {}\n",
    "    for num in fragment_nums:\n",
    "        overlap_df_for_permutations[cond][f'length_{num}'] = real_walks_with_summary_firstx_length_fractions[cond][f'length_{num}'][[\n",
    "            'Query_Name', 'Query_Length', 'Query_Start', 'Query_End', 'Strand',\n",
    "            'chrom', 'Target_ChrSize', 'start', 'end', 'Match_Length',\n",
    "            'Alignment_Length', 'Mapping_Quality', 'mid', 'Frag_Comp_Type', 'Frag_Comp_Index',\n",
    "            'Walk_Comp_Type', 'Chrom_Number', 'Comp_Type_Number', 'Comp_Index_Number', 'MaxCoord', 'MinCoord', \n",
    "            'Span', 'Max_OneCompIndex_FracOfFragments',\n",
    "            'Max_OneChrom_FracOfFragments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save these so I don't have to make them again...as pickle, entire dict\n",
    "\n",
    "f = open(f'{outDataDir}/data/220517_MRICRF_R1R2R3_real_walks_with_summary_firstx_length_fractions_dict_100kbEigs.pkl', 'wb')\n",
    "pickle.dump(real_walks_with_summary_firstx_length_fractions, f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#save overlap dfs of fragments with compartment and bin index overlaps here - these will be used for permutations\n",
    "\n",
    "f = open(f'{outDataDir}/data/220517_MRICRF_R1R2R3_real_walks_full_overlap_df_dict_100kbEigs.pkl', 'wb')\n",
    "pickle.dump(overlap_df_for_permutations, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'{outDataDir}/data/220517_MRICRF_R1R2R3_real_walks_filtered_summarized_firstx_length_dict_100kbEigs.pkl', 'wb')\n",
    "pickle.dump(real_walks_summarized_firstx_length, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make annotated txt file for GEO upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in pickled files\n",
    "\n",
    "f = open(f'{outDataDir}/220517_MRICRF_R1R2R3_real_walks_with_summary_firstx_length_fractions_dict_100kbEigs.pkl', 'rb')\n",
    "real_walks_with_summary_firstx = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_walks_df = pd.DataFrame()\n",
    "\n",
    "for cond in conditions:\n",
    "    for length in list(real_walks_with_summary_firstx[cond].keys()):\n",
    "        real_walks_with_summary_firstx[cond][length]['FirstXLength'] = length\n",
    "        real_walks_with_summary_firstx[cond][length]['Condition'] = cond\n",
    "        all_walks_df = all_walks_df.append(real_walks_with_summary_firstx[cond][length], ignore_index = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_walks_df.to_csv(f'{outDataDir}/220517_MRICRF_MC3C_FirstXFragmentsPerWalk_Annotated.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = f'{outDataDir}/220517_MRICRF_MC3C_FirstXFragmentsPerWalk_Annotated.txt'\n",
    "!gzip $df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
